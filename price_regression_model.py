# -*- coding: utf-8 -*-
"""Price Regression Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LpQ773bxK5z4-M_8z3DWz0iqiORoNsyJ

# 以下将对Airbnb2019建模
# The following code is used to build price regression model for Airbnb 2019 and then analyze the data to conclude
## 使用数据为数据预处理后生成数据
## The dataset was preprocessed by dataprocess.ipynb
## 会尽量将可复用方法前移
"""

#调包
import pandas as pd
import numpy as np
pd.set_option('display.max_columns', None)
from IPython.display import display
import matplotlib.pyplot as plt

#从原始amenity中删掉全部为0的amenity
train_am = pd.read_excel('./Amenity-train429.xlsx')
print(len(train_am))
test_am = pd.read_excel('./amenity_test429.xlsx')
print(len(test_am))
train_am.drop(['hoist'],axis=1,inplace=True)
train_am.drop(['Air purifier'],axis=1,inplace=True)
train_am.drop(['Ground floor access'],axis=1,inplace=True)
test_am.drop(['hoist'],axis=1,inplace=True)
test_am.drop(['Air purifier'],axis=1,inplace=True)
test_am.drop(['Ground floor access'],axis=1,inplace=True)

#将删掉的部分重新写入csv备用
train_am.to_csv('./Amenities_train_without_hoist.csv',index=False)
test_am.to_csv('./Amenities_test_without_hoist.csv',index=False)

#读取不包含amenity的train和test数据，此处training set是指old host的所有数据
#test是指new host的所有数据
training_set = pd.read_csv('./trainwithoutAmenities.csv')
print(len(training_set))
test = pd.read_csv('./testwithoutAmenities.csv')
print(len(test))

#拼接training set和amenities，并筛选出可出租的training数据
training_set = pd.concat([training_set,train_am],axis=1)
# display(training_set)
training_set = training_set[training_set['availability_365']>0]
training_set.describe()

#通过mean+std筛选出排除掉奇异值的数据
display(training_set[training_set['price']>648]) #mean+std
training_set = training_set[training_set['price']<=648]

#拼接test和amenities，筛出可出租数据
test = pd.concat([test,test_am],axis=1)
test = test[test['availability_365']>0]
# display(test)
test.describe()

#使用test的mean+std筛选出排除掉奇异值的数据
display(test[test['price']>481]) #mean+std
test = test[test['price']<=481]

#chutong csv use  这个是姐妹你之前要的数据 可以不用管
training_set.to_csv('old_host428.csv',index=False)
test.to_csv('new_host428.csv',index=False)

#读取出我们需要做处理的amenities，就是host可以改变的那些，5.14老师oh更新
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from scipy import stats
old_host = pd.read_csv('./old_host428.csv')
amenity = pd.read_csv('./Amenities_train_without_hoist.csv')
alist = amenity.columns.values.tolist()
display(old_host.sample(3))
alist = ['Long term stays allowed', 'Heating', 'workspace', 'Private living room', 'Indoor fireplace', 'Refrigerator', 'Breakfast', 'Beach essentials', 'Coffee maker', 'Hair dryer', 'Shampoo', 'Luggage dropoff allowed', 'Dishwasher',  'Smoking allowed', 'Cleaning before checkout', 'Game console', 'Iron', 'First aid kit', 'Dishes and silverware', 'Hot water kettle', 'Hangers', 'Air conditioning',  'BBQ grill', 'Suitable for events', 'Cozy bathroom', 'Internet', 'The fire and gases prevention',  'Comfortable sleeping environment', 'good check-in experience', 'disabled friendly facilities', 'bathtub',  'pets allowed', 'cooking basics',  'family/kids-friendly:', 'baby care',  'washer/dryer', 'TV', 'Essentials', 'Oven']
print(alist)

#数值型和类别型数据的关系---可复用Amenities
#暂时弃用 5.5更新

# for i in alist:
#     rvs1=old_host[old_host[i]==1]['price']

#     rvs2=old_host[old_host[i]==0]['price']

#     #t检验，比较的其实是两组数的点估计和理想值的比较
#     print(rvs1.mean())
#     print(rvs2.mean())
#     diff = i+' diff'
#     diff_num = round((rvs1.mean()-rvs2.mean())/rvs2.mean(),2)
#     print(diff+':',diff_num)
#     print(diff+'t检验：',stats.ttest_ind(rvs1, rvs2)) 
#     #当Pvalue较小时（p<0.05），可以拒绝原假设，例如“Heating是否存在与price无关”
#     #双样本检验，检查两个样本之间分布是否存在差异，原假设：“无差异”
#     print(diff+'双样本检验：',stats.ks_2samp(rvs1, rvs2))
# '''
# 发现不能拒绝原假设的Amenities：
# EV charger
# Beach essentials
# Luggage dropoff allowed
# Smoking allowed
# Game console
# Hot water kettle
# Ski-in/Ski-out
# Cozy bathroom
# disabled friendly facilities
# Beach/Lake
# '''

#暂时弃用 5.5更新
# delList = ['EV charger','Beach essentials'
#            ,'Luggage dropoff allowed','Smoking allowed','Game console'
# ,'Hot water kettle'
# ,'Ski-in/Ski-out'
# ,'Cozy bathroom'
# ,'disabled friendly facilities'
# ,'Beach/Lake']
# for i in delList:
#     training_set.drop([i],axis=1,inplace=True)
#     test.drop([i],axis=1,inplace=True)

#第一列为target, 剩余为feature
#将training set分出feature（x_train）和target(y_train)
y_train = training_set['price']
x_train = training_set.drop(['price'],axis=1)
print(len(y_train),len(x_train))
#对于new_host的test,分出feature（x_test）和target(y_test)
y_test = test['price']
x_test = test.drop(['price'],axis=1)

#针对old_host划分训练集&测试集，本测试集用于评估模型准确程度
#训练集：oh_x_train oh_y_train
#测试集：oh_x_test oh_y_test
#至于new_host 如果出现的predict与实际偏差越大，越能说明我们模型和建议的必要性
from sklearn.cross_validation import train_test_split
oh_x_train,oh_x_test,oh_y_train,oh_y_test = train_test_split(x_train,y_train,train_size=0.8)
print(len(oh_x_train),len(oh_x_test),len(oh_y_train),len(oh_y_test))

# Commented out IPython magic to ensure Python compatibility.
#以下是用于evaluate的函数，在每一个model里都复用了
#评估标准也写在函数的注释里啦
#These are the metrics used to evaluate model performance
def evaluate_model(model,y1,py1,y2,py2,l):
    #y1 old host test true value
    #py1 old host test predict value
    #y2 py2 new host
    #l linear 1 or not
    if l == 1:
        print('Coefficients: \n', model.coef_)
    #平均绝对误差是非负值，模型越好MAE越接近零
    print('mean_absolute_error: %.2f'
#       % mean_absolute_error(y1, py1))
    print('new host mean_absolute_error: %.2f'
#       % mean_absolute_error(y2, py2))
    #均方误差是非负值，模型越好MSE越接近零。
    print('Mean squared error: %.2f'
#       % mean_squared_error(y1, py1))
    print('new host Mean squared error: %.2f'
#       % mean_squared_error(y2, py2))
    #中值绝对误差是非负值，模型越好越接近零。
    print('median_absolute_error: %.2f'
#       % median_absolute_error(y1, py1))
    print(' new host median_absolute_error: %.2f'
#       % median_absolute_error(y2, py2))
    #最佳为1，模型越差值越小
    print('explained_variance_score: %.2f'
#       % explained_variance_score(y1, py1))
    print(' new host explained_variance_score: %.2f'
#       % explained_variance_score(y2, py2))
    #最佳为1
    print('Coefficient of determination: %.2f'
#       % r2_score(y1, py1))
    print('new host Coefficient of determination: %.2f'
#       % r2_score(y2, py2))
    fig = plt.figure(figsize=(200, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80
    axes = fig.add_subplot(1, 1, 1)#设置查看的子图
    line1, = axes.plot(range(len(py1)), py1, 'b--', label='predict', linewidth=2)
    line2, = axes.plot(range(len(py1)), y1, 'g', label='true')
    axes.grid()
    fig.tight_layout()
    plt.legend(handles=[line1, line2])
    plt.title('old host拟合曲线')
    plt.show()
    
    fig = plt.figure(figsize=(200, 3))  # dpi参数指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80
    axes = fig.add_subplot(1, 1, 1)#设置查看的子图
    line3, = axes.plot(range(len(py2)), py2, 'r--', label='predict', linewidth=2)
    line4, = axes.plot(range(len(py2)), y2, 'g', label='true')
    axes.grid()
    fig.tight_layout()
    plt.legend(handles=[line3, line4])
    plt.title('new host拟合曲线')
    plt.show()

"""# 以下为建模部分
进行比对的指标为evaluate_model中5个指标，见上面的block。具体评估标准已经写在函数的注释里了，请查看。
此外，还对old_host和new_host分别作图，如果图很小，可以双击放大！！！
"""

#筛选出0较多的测试列，就是我们5.14参加oh老师说的要的单个example
#filter the single example used to analyze
old_test = test 
for i in alist:
    if(len(old_test)>10):
        old_test = old_test[old_test[i]<1]
    else:
        break
display(old_test)
example_y = old_test['price']
example_x = old_test.drop(['price'],axis=1)
change_example_x = old_test.drop(['price'],axis=1)
for i in alist:
    change_example_x[i] = 1
print(change_example_x)

#这个是对全体不含我们可以改变的amenities（为0）的new host数据变为1
#以及将每个模型代入，评估整体变化率的函数
#The function used to evaluate change ratio
def amenitiesTest(model,test,amelist):
    amdict = {}
    for i in amelist:
        oldtest = test[test[i]<1]
        newtest = test[test[i]<1]
        newtest[i] = 1
        y_am_test = oldtest['price']
        x_am_oldtest = oldtest.drop(['price'],axis=1)
        x_am_newtest = newtest.drop(['price'],axis=1)
        reg_pred_old = model.predict(x_am_oldtest)
        reg_pred_new = model.predict(x_am_newtest)
        m = np.median(reg_pred_old[reg_pred_old > 0])
        reg_pred_old[reg_pred_old == 0] = m
        a = reg_pred_new/reg_pred_old-1
        amdict[i] = format(np.mean(a),'.2%')
    return amdict

def example_change(model):
    #这里是ece今天问的 我们要用“用旧数据预测的y”和“用新数据预测的y”算ratio
    #use prices predicted by original data and current data to caculate the ratio
    old_example_predict_y = model.predict(example_x)
    pred_example = model.predict(change_example_x)
    change_ratio = pred_example/old_example_predict_y-1
    change_ratio = format(np.mean(change_ratio),'.2%') 
    print('旧预测价格:',np.float(old_example_predict_y)) #price predicted by original data 
    print('新预测价格：',np.float(pred_example)) #price predicted by current data
    print('价格变化率：',change_ratio) #change ration

#线性回归 Linear Reg
from sklearn import linear_model
from sklearn.metrics import explained_variance_score,mean_absolute_error,mean_squared_error,r2_score,median_absolute_error
lin_reg = linear_model.LinearRegression()
#训练模型 train
lin_reg.fit(oh_x_train,oh_y_train)
#测试模型 test
lin_reg_pred = lin_reg.predict(oh_x_test)
#用new host数据测试模型 use modified data to test
lin_reg_pred1 = lin_reg.predict(x_test)
#对两个测试的评估 evaluate for both results
evaluate_model(lin_reg,oh_y_test,lin_reg_pred,y_test,lin_reg_pred1,1)
#整体amenities从0→1的average ratio变化 show the avg ratio changes
print(amenitiesTest(lin_reg,test,alist))
#单个example的变化 for single example of business case
example_change(lin_reg)

#Logistics Regression
#未除去异常值 -0.25
#除去异常值 exclude the outliner
from sklearn.linear_model import LogisticRegression
log_reg = linear_model.LogisticRegression()
log_reg.fit(oh_x_train,oh_y_train)
log_reg_pred = log_reg.predict(oh_x_test)
log_reg_pred1 = log_reg.predict(x_test)
evaluate_model(lin_reg,oh_y_test,log_reg_pred,y_test,log_reg_pred1,1)
print(amenitiesTest(log_reg,test,alist))
example_change(log_reg)

#SVR linear kernel
#未除去异常值0.01
from sklearn import svm
svr_reg = svm.SVR(kernel='linear', C=1.25)
svr_reg.fit(oh_x_train,oh_y_train)
svr_reg_pred = svr_reg.predict(oh_x_test)
svr_reg_pred1 = svr_reg.predict(x_test)
evaluate_model(svr_reg,oh_y_test,svr_reg_pred,y_test,svr_reg_pred1,1)
print(amenitiesTest(svr_reg,test,alist))
example_change(svr_reg)

#SVR rbf
#未除去异常值0.06
from sklearn import svm
svr_regrbf = svm.SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)
svr_regrbf.fit(oh_x_train,oh_y_train)
svr_regrbf_pred = svr_regrbf.predict(oh_x_test)
svr_regrbf_pred1 = svr_regrbf.predict(x_test)
evaluate_model(svr_regrbf,oh_y_test,svr_regrbf_pred,y_test,svr_regrbf_pred1,0)
print(amenitiesTest(svr_regrbf,test,alist))
example_change(svr_regrbf)

#SVR poly
#未除去异常值0.03
from sklearn import svm
svr_regpoly = svm.SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,coef0=1)
svr_regpoly.fit(oh_x_train,oh_y_train)
svr_regpoly_pred = svr_regpoly.predict(oh_x_test)
svr_regpoly_pred1 = svr_regpoly.predict(x_test)
evaluate_model(svr_regpoly,oh_y_test,svr_regpoly_pred,y_test,svr_regpoly_pred1,0)
print(amenitiesTest(svr_regpoly,test,alist))
example_change(svr_regpoly)

#NN 
#未除去异常值 0.3
from sklearn.neural_network import MLPRegressor
regr = MLPRegressor(random_state=1, max_iter=500).fit(oh_x_train,oh_y_train)
nn_reg_pred = regr.predict(oh_x_test)
nn_reg_pred1 = regr.predict(x_test)
evaluate_model(regr,oh_y_test,nn_reg_pred,y_test,nn_reg_pred1,0)
print(amenitiesTest(regr,test,alist))
example_change(regr)

#Ridge
from sklearn.linear_model import Ridge,RidgeCV
#未除去异常值 0.09
Lambdas = np.logspace(-5,2,200)
rigdeCV = RidgeCV(alphas=Lambdas,normalize=True,scoring='neg_mean_squared_error',cv=15)
rigdeCV.fit(oh_x_train,oh_y_train)
predictedResult = rigdeCV.predict(oh_x_test)
predictedResult1 = rigdeCV.predict(x_test)
evaluate_model(rigdeCV,oh_y_test,predictedResult,y_test,predictedResult1,0)
print(amenitiesTest(rigdeCV,test,alist))
example_change(rigdeCV)

#EN
from sklearn.linear_model import ElasticNet
#未除去异常值0.08
enet = ElasticNet(alpha=0.1, l1_ratio=0.7)

enet.fit(oh_x_train,oh_y_train)
y_pred_enet = enet.predict(oh_x_test)
y_pred_enet1 = enet.predict(x_test)
evaluate_model(enet,oh_y_test,y_pred_enet,y_test,y_pred_enet1,0)
print(amenitiesTest(enet,test,alist))
example_change(enet)

#KNN
from sklearn.neighbors import KNeighborsRegressor
neigh = KNeighborsRegressor() #default 5
neigh.fit(oh_x_train,oh_y_train)
y_nei_pred = neigh.predict(oh_x_test)
y_nei_pred1 = neigh.predict(x_test)
evaluate_model(neigh,oh_y_test,y_nei_pred,y_test,y_nei_pred1,0)
print(amenitiesTest(neigh,test,alist))
example_change(neigh)

#RF
#0.65
from sklearn.ensemble import RandomForestRegressor
RF = RandomForestRegressor()
RF.fit(oh_x_train,oh_y_train)
y_rf_pred = RF.predict(oh_x_test)
y_rf_pred1 = RF.predict(x_test)
evaluate_model(RF,oh_y_test,y_rf_pred,y_test,y_rf_pred1,0)
print(amenitiesTest(RF,test,alist))
example_change(RF)

#Gradient R
#0.57
from sklearn.ensemble import GradientBoostingRegressor
est = GradientBoostingRegressor()
est.fit(oh_x_train,oh_y_train)
y_est_pred = est.predict(oh_x_test)
y_est_pred1 = est.predict(x_test)
evaluate_model(est,oh_y_test,y_est_pred,y_test,y_est_pred1,0)
print(amenitiesTest(est,test,alist))
example_change(est)

